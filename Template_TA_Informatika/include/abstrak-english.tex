\begin{abstracteng}

\textit{Visual Question Answering (VQA) is a task to answer questions based on images. In the medical world, VQA can help health experts to get information from medical images. However, medical images have their own challenges such as complex question variations and high levels of abstraction. Thus, it requires a VQA model that can handle these challenges. This research conducts experiments with two models, VGG19-LSTM and BLIP with PathVQA and VQA-RAD datasets. The VGG19-LSTM model combines Convolutional Neural Network (CNN) with Long Short-Term Memory (LSTM). BLIP is a unified model for vision-language tasks that uses Vision Transformers (ViT) as image encoders and transformers as text encoders. The experimental results show the superiority of the BLIP model in both datasets. BLIP trained with the PathVQA dataset with hyperparameter configuration of 15 epochs, batch size 8, and learning rate $1 \times 10^{-5}$ after question augmentation achieves an accuracy of 83.91\%, close-ended question accuracy of 97.43\%, and open-ended question accuracy of 66.15\%. After that, the BLIP model trained with the VQA-RAD dataset with hyperparameter configuration of 45 epochs, batch size 8, and learning rate $5 \times 10^{-5}$ after question augmentation achieves an accuracy of 82.86\%, close-ended question accuracy of 87.85\%, and open-ended question accuracy of 76.82\%. In the inference stage, the quantized BLIP model shows better performance than without quantization. Before quantization, the size of the BLIP model is 1467.73 MB with an inference time of 0.24 seconds on the PathVQA dataset, and 1467.73 MB with an inference time of 0.21 seconds on the VQA-RAD dataset. After quantization, the size of the BLIP model becomes 508.21 MB with an inference time of 0.20 seconds on the PathVQA dataset, and 508.20 MB with an inference time of 0.17 seconds on the VQA-RAD dataset.}

\bigskip
\noindent
\textit{\textbf{Keywords :}} \textit{Visual Question Answering}, \textit{Convolutional Neural Network}, \textit{Long Short-Term Memory}, \textit{Transformer} VGG19-LSTM, BLIP, \textit{Medical Image}
\end{abstracteng}